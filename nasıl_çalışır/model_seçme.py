
from sklearn.datasets import load_diabetes

data = load_diabetes()
x = data.data
y = data.target

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)
# 	â€¢	random_state: AynÄ± bÃ¶lmeyi tekrar Ã¼retmek iÃ§in sabit sayÄ±


# cross_val_score

# veriyi k-fold gibi yÃ¶ntemlerle bÃ¶ler ve bu modeller Ã¼zerinde test yapÄ±lÄ±r.

# cv deÄŸeri kat sayÄ±sÄ± veya Ã§apraz doÄŸrulama deÄŸeridir. 
# hangi metriÄŸi kullanacaÄŸÄ±nÄ± belirtir
'''
Ã§apraz doÄŸrulama: eÄŸitim verisini ezber yapmadan, gerÃ§ek hayatta nasÄ±l performans gÃ¶stereceÄŸini Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r.
k-fold Cross validation: veri seti cv deÄŸerindeki sayÄ± kadar parÃ§alara bÃ¶lÃ¼nÃ¼r. genelde 5 veya 10
her seferinde bir parÃ§a test seti kalanÄ± train seti olur.
bu iÅŸlem k kez tekrarlanÄ±r.
her seferinde model yeniden eÄŸitilir ve test edilir. 
SonuÃ§ta k adet doÄŸruluk/f1/vs gibi score deÄŸerleri bulunur.
AmaÃ§ her parÃ§alÄ± veri bir kez test veri seti ve k-1 kez eÄŸitim seti olmuÅŸtur. modelin daha tutarlÄ± davranmasÄ± amaÃ§lanÄ±r.

verinin daÄŸÄ±lÄ±mÄ± dengesiz ise tek test veri seti yanÄ±ltÄ±cÄ± olabileceÄŸi iÃ§in bu yÃ¶ntem kullanÄ±lÄ±r.

Scoring parametresi neden seÃ§ilir?
Modelin neye gÃ¶re iyi olduÄŸunu belirleyen Ã¶lÃ§Ã¼ttÃ¼r. 
Modelin baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in bir kriter seÃ§miÅŸ oluruz. 

Model seÃ§imi neden fark yaratabilir? 

Degesiz veri seti varsa accuracy deÄŸeri yÃ¼ksek olsa bile model iÅŸe yaramaz olabilir. 
Tahminlerde dikkatli olunmasÄ± gereken yerlerde presicion, recall, f1 daha uygun olabilir.

DoÄŸru sÄ±nÄ±flama kadar, yanlÄ±ÅŸ sÄ±nÄ±flamanÄ±n maliyetide Ã¶nemli ise, f1 veya Ã¶zel metrikler kullanÄ±lÄ±r.

Ã–rnek olarak bir fraud detection modelimiz var, %99 accuracy alÄ±yoruz, verilerin %99 u fraud deÄŸil.
ama fraudlarÄ± hiÃ§ bulamÄ±yoruz, Bu modelin gerÃ§ekte iÅŸe yaramadÄ±ÄŸÄ±nÄ± gÃ¶sterir. recall deÄŸeri yÃ¼ksekse mesela
fraudlarÄ± yakaladÄ±ÄŸÄ±mÄ±z anlamÄ±na gelir ve bu deÄŸerli bir bilgidir.

Hangi modeli neden kullanmalÄ±yÄ±m ? 

Problem tÃ¼rÃ¼ tanÄ±mlamasÄ± yapmak Ã¶nemlidir. 
dengesiz sÄ±nÄ±flar var ise, %95 hayÄ±r %5 evet gibi, (presicion, recall, f1, roc_auc) kullanÄ±lÄ±r.
eÅŸit sayÄ±da sÄ±nÄ±f var ise, %50 evet, %50 hayÄ±r gibi (accuracy, f1) kullanÄ±lÄ±r.
hatalarÄ±n maliyeti farklÄ± ise yanlÄ±ÅŸ negatif Ã§ok tehlikeli, (recall Ã¶nce yaka )
yanlÄ±ÅŸ pozitif tehlikeli, yanlÄ±ÅŸ kiÅŸiye kredi vermek (precision)
regresyon modelleri, sÃ¼rekli deÄŸer tahmini (fiyat, sÄ±caklÄ±k) (r2, neg_mean_squared_error, neg_mean_absolute_error)


Problem: SÄ±nÄ±flandÄ±rma mÄ±?
â”œâ”€â”€ Dengeli mi?
â”‚   â””â”€â”€ Evet â†’ accuracy / f1
â”‚   â””â”€â”€ HayÄ±r â†’ recall / precision / f1 / roc_auc
â””â”€â”€ Regresyon mu?
    â”œâ”€â”€ BÃ¼yÃ¼k hatalar mÄ± Ã¶nemli? â†’ mse
    â”œâ”€â”€ Ortalama hata mÄ± Ã¶nemli? â†’ mae
    â””â”€â”€ AÃ§Ä±klama oranÄ± mÄ± Ã¶nemli? â†’ r2

Ã¶neri olarka modeli eÄŸitirken farklÄ± kombinasyonlar kullanarak hangisinin verim iÃ§in mantÄ±klÄ± olan metrik olduÄŸunu Ã¶ÄŸrenebilirim.
'''
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=5, scoring="accuracy")
print(scores.mean())



'''
bir modelin, tÃ¼m veri seti Ã¼zerinde Ã§apraz doÄŸrulama yaparak tahmin ettiÄŸi sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r. yani 
her bir Ã¶rnek, eÄŸitim sÄ±rasÄ±nda gÃ¶rÃ¼lmemiÅŸ bir fold a denk getirilir ve bu fold'daki test verileri iÃ§in tahmin yapÄ±lÄ±r.
SonuÃ§ta modelin gerÃ§ek hayatta nasÄ±l tahmin yapacaÄŸÄ±nÄ± daha yakÄ±n bir tahmin Ã§Ä±ktÄ±sÄ± elde edilir. 

Her bir veri noktasÄ±nÄ±n eÄŸitim sÄ±rasÄ±nda gÃ¶rÃ¼lmeden tahmin edilmesini saÄŸlar. 
BÃ¶ylece overfitting riski olmadan tahmin sonuÃ§larÄ± elde edilir.

Diyelim ki 100 Ã¶rnek var, cv=5 yaptÄ±n.
	â€¢	cross_val_score: â€œFold 1 â†’ accuracy: 0.92, Fold 2 â†’ 0.89â€¦â€ gibi skorlar dÃ¶ner.
	â€¢	cross_val_predict: â€œVeri[0] iÃ§in 1, Veri[1] iÃ§in 0, Veri[2] iÃ§in 1â€¦â€ gibi tahminler dÃ¶ner. BunlarÄ± confusion_matrix vs iÃ§in kullanabilirsin.

Neden kullanÄ±lÄ±r: 
modeli henÃ¼z tam eÄŸitmeden confusion matrix Ã¼retmek, ROC ve precision-recall eÄŸrileri Ã§izmek 
AmaÃ§: Modelin tÃ¼m veri Ã¼zerindeki tahminlerini almak, 	â€¢	Ne dÃ¶ner?: Her gÃ¶zlem iÃ§in tahmin (y_pred)
TÃ¼m veri iÃ§in Ã§apraz doÄŸrulama tahminleri dÃ¶ner. 
her Ã¶rneÄŸin tahmin sonuÃ§larÄ±nÄ± elde etmiÅŸ oluruz. 
EÄŸer â€œÅŸu gÃ¶zleme model ne tahmin ettiâ€ sorusunu soruyorsan,
cross_val_predictâ€™i kullanÄ±rsÄ±n.

EÄŸer â€œmodel ne kadar baÅŸarÄ±lÄ±â€ diye bakÄ±yorsan,
cross_val_score daha doÄŸru olur.
'''

from sklearn.model_selection import cross_val_predict
scores = cross_val_predict()



'''
scikit-learn da model parametre ayarÄ± yapmak iÃ§in kullanÄ±lÄ±r.
hyperparmeter tuning olarak geÃ§er. bir modelin hiperparametrelerini denemek iÃ§in kullandÄ±ÄŸÄ±mÄ±z bir araÃ§tÄ±r.
model parametrelerini deÄŸiÅŸtirerek en iyi kombinasyonu elde etmemiz gere. 
Modelin hiperparametrelerini farklÄ± kombinasyonlarla Ã§apraz doÄŸrulama yaparak test eder. 
en iyi sonucu veren ayarlarÄ± bulur. 
Parametre olarak; bir model alÄ±r, denenecek parametreler bir dict veya list olabilir, hangi metric ile
baÅŸarÄ± oranÄ± belirlenecek bu yÃ¼zden bir metric deÄŸeri alÄ±r, cv ile cross validation deÄŸeri alÄ±r, eÄŸitim aÅŸamasÄ±nda Ã§Ä±ktÄ± istiyorsa
ve paralel iÅŸlem sayÄ±sÄ± parametrelerini alÄ±r. 

Ne zaman kullanÄ±lÄ±r: 
KNN, SVC, RandomForest, LogisticRegression, GradientBoosting gibi modellerin parametrelerini optimize etmek iÃ§in
elimizde doÄŸrulama verisi yoksa (yada overfitting'den kaÃ§Ä±nmak istiyorsak)
ROC, recall, precision gibi metriklere gÃ¶re ayar yapmak iÃ§in 

KullanÄ±lan modele gÃ¶re parametre deÄŸiÅŸmektedir.

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
print(model.get_params())
Her modelin parametresini bu ÅŸekilde Ã§ekebiliriz.
param_grid = {
    'C': [0.1, 1, 10],
    ...
}
bÃ¶yle bir girdide c deÄŸeri iÃ§in 3 farklÄ± deÄŸer denemiÅŸ olacaÄŸÄ±z.
'''
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
param_grid = {'C': [0.1, 1, 10]}
x = 5
grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')
grid.fit(x, y)
print(grid.best_params_)





'''
girdsearchcv yapÄ±sÄ±na Ã§ok benzer daha hÄ±zlÄ± ve daha esnektir. belirtilen hiperparametre daÄŸÄ±lÄ±mÄ±ndan belirli sayÄ±da rastgele Ã¶rnek alÄ±r.
Her Ã¶rnek iÃ§in modeli eÄŸitir ve performansÄ±nÄ± deÄŸerlendirir. 
Daha az kombinasyonla hÄ±zlÄ±ca iyi souÃ§lar bulmak iÃ§in kullanÄ±lÄ±r. 
parametre olarak model, model iÃ§indeki parametrelerin kurgusu, kaÃ§ farklÄ± kombinasyon denenecek, hedef metrik, kaÃ§ katmanlÄ± cross validation olacak
random_state deÄŸeri(her zmana aynÄ± verilerle bÃ¶lÃ¼nsÃ¼n diye) ve iÅŸ parÃ§acÄ±ÄŸÄ± olarak parametreler alÄ±r.

parametre kombinasyonlarÄ± Ã§ok fazlaysa ve hÄ±zlÄ± bir sonuÃ§ isteniyorsa kullanÄ±labilir. Ã§ok hassas ayarlama
gerekiyorsa ilk olarak random kullanÄ±lÄ±r parametreler daraltÄ±rlÄ±r ve grid ile tekrardan eÄŸitim yapÄ±lÄ±r.

Sadece sabit listelerle deÄŸil daÄŸÄ±lÄ±mlarla da Ã§alÄ±ÅŸÄ±r, bu sayede Ã§ok geniÅŸ deÄŸerler Ã¼zerinde Ã¶rnekleme yapÄ±labilir.

uniform (loc, scale) loc:baÅŸlangÄ±c scale: aralÄ±k 
randint (low, high) tam sayÄ± aralÄ±ÄŸÄ± 
loguniform (a, b) logaritmik olarak daÄŸÄ±lmÄ±ÅŸ deÄŸerler (Ã§ok yaygÄ±n)
from scipy.stats import loguniform

param_dist = {
    'C': loguniform(0.01, 100),  # Daha iyi arama iÃ§in
}

'''
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform

param_dist = {'C': uniform(0.1, 10)}
search = RandomizedSearchCV(LogisticRegression(), param_dist, n_iter=10, cv=5)
search.fit(X, y)




'''
veri kÃ¼mesini k eÅŸit parÃ§aya bÃ¶ler, normal cross validation yapÄ±sÄ±ndadÄ±r. sÄ±nÄ±f daÄŸÄ±lÄ±mÄ± dengesiz ise 
kullanÄ±lmasÄ± tavsiye edilmez. 

** veri noktasÄ± kavramÄ± bir veri kÃ¼mesindeki her biri satÄ±rÄ± temsil etmektedir.
eÄŸer cv= 5 ise 10 veri noktan varsa, 10 deÄŸeri 5 e bÃ¶lÃ¼nÃ¼r. 0-1, 2-3, 4-5 ... ÅŸeklinde palaÅŸÄ±lÄ±r
n_splits: cv deÄŸeri (kaÃ§ parÃ§aya bÃ¶lÃ¼necek)
shuffle: veiriyi karÄ±ÅŸtÄ±rmak istersen true 
random_state
'''

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, KFold

model = LogisticRegression()
kf = KFold(n_splits=5, shuffle=True, random_state=42)

scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')
print("DoÄŸruluk OrtalamasÄ±:", scores.mean())





'''
StratifiedKFold, veriyi bÃ¶lerken her fold'da sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± korumaya Ã§alÄ±ÅŸÄ±r, veride dengesiz sÄ±nÄ±flar var ise 
her train test grubunda bu oranÄ± sabit tutmaya Ã§alÄ±ÅŸÄ±r. 
bir sÄ±nÄ±flandÄ±rma problemi Ã§Ã¶zÃ¼yorsak, dengesizlik varsa kullanÄ±labilir. Regression problemlerinde gerkli deÄŸildir. 

Dikkat: skf.split(X, y) â†’ hem X hem y verilmelidir. Ã‡Ã¼nkÃ¼ StratifiedKFold, yâ€™yi dikkate alarak bÃ¶lme yapar.
'''

from sklearn.model_selection import StratifiedKFold
import numpy as np

X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])  # 5 tane 0, 5 tane 1

skf = StratifiedKFold(n_splits=2)

for train_index, test_index in skf.split(X, y):
    print("Train:", train_index, "Test:", test_index)
    print("Train labels:", y[train_index], "Test labels:", y[test_index])





'''
Veriyi zaman sÄ±rasÄ±na gÃ¶re artan ÅŸekliyle bÃ¶yler. Yani geÃ§miÅŸ verilerle modeli eÄŸitir, yeni verilerle
modeli test eder. 
finans, saÄŸlÄ±k, hava durumu gibi zamana baÄŸlÄ± verilerde kullanÄ±lÄ±r. 
TimeSeriesSplit(n_splits=3) ile:
	â€¢	1. Fold:
	â€¢	Train â†’ [1, 2, 3, 4]
	â€¢	Test  â†’ [5, 6]
	â€¢	2. Fold:
	â€¢	Train â†’ [1, 2, 3, 4, 5, 6]
	â€¢	Test  â†’ [7, 8]
	â€¢	3. Fold:
	â€¢	Train â†’ [1, 2, 3, 4, 5, 6, 7, 8]
	â€¢	Test  â†’ [9, 10]

    
Train veri seti her seferinde geniÅŸliyor, asla geriye gitmiyor. 
test veri seti her seferinde daha sonraki zamanÄ± kapsÄ±yor. 

neden diÄŸerlerinden farklÄ±?
Diyelimki zaman serisi olsun verimizde, borsa fiyatlarÄ± olsun elimizde, klasik kfold kullanÄ±rsak belkide 
gelecekteki verilerle geÃ§miÅŸi tahmin etmiÅŸ olacaÄŸÄ±z, bu veri sÄ±zÄ±ntÄ±sÄ± anlamÄ±na gelir, (data leakage) olur modeli hatalÄ± deÄŸerlendirir.
n_splits: kaÃ§ adet flod oluÅŸturulacak
max_train_size: eÄŸitim max uzunluÄŸunu sÄ±nÄ±rlayabiliriz. 
test_size: test set uzunluÄŸunu kontrol edebiliriz. 
'''
from sklearn.model_selection import TimeSeriesSplit
import numpy as np

X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
tscv = TimeSeriesSplit(n_splits=3)

for train_index, test_index in tscv.split(X):
    print("Train:", train_index, "Test:", test_index)






'''
klasik kfold'dan daha esnek ve rastgele versiyonudur. Ã–zellikle bÃ¼yÃ¼k veri setlerinde veya daha esnek bÃ¶lme ihtiyaÃ§larÄ±nda tercih edilir. 
Veriyi rastgele olarak eÄŸitim ve test kÃ¼melerine belirli oranlarla bÃ¶ler, bu iÅŸlemi birden fazla kez tekrarlar. 
Her flodda rastgele train ve test ayrÄ±mÄ± yapar, istediÄŸimiz kadar bu iÅŸlemden yapabilri.z
 
overfitting riskine karÅŸÄ± modeli daha rastgele durumlara karÅŸÄ± test etmek iÃ§in. 
modelin kararlÄ±lÄ±ÄŸÄ±nÄ± gÃ¶rmek iÃ§in 

ShuffleSplit, zaman serisi verilerde kullanÄ±lmamalÄ±dÄ±r, Ã§Ã¼nkÃ¼ rastgele karÄ±ÅŸÄ±m (shuffle) 
geÃ§miÅŸ ve gelecek dengesini bozar â†’ data leakage olur.
'''

from sklearn.model_selection import ShuffleSplit

X = np.arange(10)  # Ã–rnek veri
ss = ShuffleSplit(n_splits=3, test_size=0.3, train_size=0.7, random_state=42)

for train_index, test_index in ss.split(X):
    print("Train:", train_index, "Test:", test_index)




'''
Bu yÃ¶ntem, ShuffleSplit ile StratifiedKFoldâ€™un gÃ¼zel bir birleÅŸimi gibi dÃ¼ÅŸÃ¼nebilirsin.


veriyi rastgele ama sÄ±nÄ±f oranlarÄ±nÄ± koruyarak eÄŸitim ve test setlerine bÃ¶ler. 
Yani sÄ±nÄ±flar orantÄ±lÄ± bir ÅŸekilde hem eÄŸitim hem test kÃ¼melerine daÄŸÄ±lÄ±r. dengesiz (imbalanced) veri setlerinde 
kullanÄ±mÄ± Ã¶nemlidir. 
'''
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)

sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)

for train_index, test_index in sss.split(X, y):
    print("Train:", train_index, "Test:", test_index)





'''
Her bir veri noktasÄ±nÄ± ayrÄ± ayrÄ± test seti olarak kullanÄ±r. kalan tÃ¼m verileri eÄŸitim seti yapar. 
n tane model eÄŸitilir. her seferinde sadece bir Ã¶rnek test olarak ayrÄ±lÄ±r, n-1 model eÄŸitilir. 
her Ã¶rnek tam olarak 1 kez test setinde yer alÄ±r. 

model n kez eÄŸitilir. Ã§ok hassas Ã¶lÃ§Ã¼m yapÄ±lÄ±r. overfitting riski dÃ¼ÅŸÃ¼k. KÃ¼Ã§Ã¼k veri setlerinde kullanÄ±lÄ±r. 
 BÃ¼yÃ¼k veri setlerinde: Ã‡Ã¼nkÃ¼ her Ã¶rnek iÃ§in bir model eÄŸitmek zaman alÄ±r (Ã¶rneÄŸin 10.000 veri varsa â†’ 10.000 model).
  Nerede kullanÄ±lÄ±r?
	â€¢	Biyoistatistik
	â€¢	Medikal tahmin
	â€¢	KÃ¼Ã§Ã¼k Ã¶rneklemli psikoloji deneyleri
	â€¢	Finansal zaman serisi modelleme (kÄ±sÄ±tlÄ± veriyle)
'''
from sklearn.model_selection import LeaveOneOut
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)

loo = LeaveOneOut()

for train_index, test_index in loo.split(X):
    print("Train:", train_index, "Test:", test_index)
    # X_train, X_test = X[train_index], X[test_index]






'''
SÃ¼per, ÅŸimdi de daha genel ama nadiren kullanÄ±lan bir teknikle devam edelim:

ğŸ”„ LeavePOut Nedir?

Leave-P-Out (LPO), her seferinde tam olarak p veri noktasÄ± test setine, 
kalan veriler eÄŸitim setine konur. Bu iÅŸlem, tÃ¼m p kombinasyonlarÄ± iÃ§in tekrar edilir.
EÄŸer elimizde n Ã¶rnek varsa, her defasÄ±nda p tanesini test iÃ§in ayÄ±rÄ±yoruz.
Bu durumda kaÃ§ kombinasyon olacaÄŸÄ±nÄ± tahmin edebilir misin?

 C(n, p) farklÄ± eÄŸitim/test bÃ¶lmesi oluÅŸur (kombinasyon sayÄ±sÄ±).

Ã–rnek:
n = 5, p = 2 â‡’ C(5, 2) = 10 farklÄ± bÃ¶lme olur.
KÃ¼Ã§Ã¼k ve hassas veri setlerinde
âœ… Model performansÄ±nÄ± en geniÅŸ kombinasyonlarla test etmek gerektiÄŸinde
âŒ BÃ¼yÃ¼k veri setlerinde (kombinasyon sayÄ±sÄ± hÄ±zla patlar!)

'''
from sklearn.model_selection import LeavePOut
import numpy as np

X = np.array([[1], [2], [3], [4]])
y = np.array([1, 2, 3, 4])

lpo = LeavePOut(p=2)

for train_index, test_index in lpo.split(X):
    print("Train:", train_index, "Test:", test_index)





'''
verileri gruplara gÃ¶re bÃ¶len ve aynÄ± gruplar iÃ§indeki Ã¶rneklerin hem eÄŸitimde hem testte aynÄ± anda 
yer almamasÄ±nÄ± garanti eden bir Ã§apraz doÄŸrulama tekniÄŸidir. 

eÄŸer aynÄ± kiÅŸiye ait birden fazla gÃ¶zlem varsa (hastalÄ±k Ã¶lÃ§Ã¼mleri, alÄ±ÅŸveriÅŸ. )
aynÄ± mÃ¼ÅŸterinin farklÄ± zamanlardaki haraketileri varsa, 
aynÄ± sensÃ¶r cihazÄ±ndan alÄ±nan veri varsa, 
aynÄ± Ã¼rÃ¼n kullanÄ±cÄ± veya kategoriye ait alt veri noktalarÄ± varsa 
AmaÃ§; aynÄ± gruba ait veriler aynÄ± katmanda kalmalÄ± hem eÄŸitim hem testte bulunmalÄ±. 

aynÄ± deÄŸeri taÅŸÄ±yan Ã¶rnekler birlikte tutulur. 
zorunlu olarak grups argÃ¼manÄ± verilir. 
sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±na dikkat etmez, sadece grup daÄŸÄ±lÄ±mÄ±na bakar. 
TÃ¼m gruplar her flodda ya test ya da eÄŸitim setinde yer alÄ±r. 
diyelim ki 100 hasta var, ve her birinden 5 farklÄ± kan Ã¶rneÄŸi alÄ±ndÄ± Bu durumda grups dizisi ÅŸÃ¶yle olur.
groups = np.repeat(np.arange(100), 5)  # Her hasta bir grup

normal kFlod kullanmak kaÃ§aÄŸa sebep olur. aynÄ± hastanÄ±n verisi hem train hem test'e gidebilir. 
'''

from sklearn.model_selection import GroupKFold
import numpy as np

X = np.array([[1], [2], [3], [4], [5], [6]])
y = np.array([1, 1, 1, 0, 0, 0])
groups = np.array([1, 1, 2, 2, 3, 3])  # Grup numaralarÄ±

gkf = GroupKFold(n_splits=3)

for train_idx, test_idx in gkf.split(X, y, groups):
    print("Train:", train_idx, "Test:", test_idx)
